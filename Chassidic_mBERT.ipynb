{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPGYXVkkUR+qINED+x7Ty5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbeyderman/gbeyderman/blob/gh-pages/Chassidic_mBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ll use a combination of Hebrew Chassidus texts and English translations/commentaries to maintain mBERT’s bilingual strengths.\n",
        "\n",
        "Action Steps:\n",
        "Hebrew Texts: Scrape digitized Hebrew texts from the Chabad Library (https://chabadlibrary.org/books).\n",
        "English Texts: Collect English translations of Chabad texts (e.g., Lessons in Tanya, Chassidic discourses from Kehot, and other sources).\n",
        "Combine Datasets:\n",
        "Merge Hebrew and English texts into a bilingual dataset.\n",
        "Ensure a balance between the two languages to retain mBERT's multilingual capabilities."
      ],
      "metadata": {
        "id": "9a5Np9j2sqTx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qorPKf9MsQNA",
        "outputId": "5dff3838-aaae-4a47-8c0b-28e952431053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: chabad_texts_hebrew/book1.txt\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# Directories for storing text\n",
        "OUTPUT_DIR_HE = \"chabad_texts_hebrew\"\n",
        "OUTPUT_DIR_EN = \"chabad_texts_english\"\n",
        "os.makedirs(OUTPUT_DIR_HE, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR_EN, exist_ok=True)\n",
        "\n",
        "# Example book URLs (extend this list)\n",
        "hebrew_links = [\n",
        "    \"https://chabadlibrary.org/books/book1\",  # Replace with real URLs\n",
        "]\n",
        "\n",
        "\n",
        "def scrape_and_save(url, output_dir):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        text = soup.get_text()\n",
        "        filename = os.path.join(output_dir, url.split(\"/\")[-1] + \".txt\")\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text)\n",
        "        print(f\"Saved: {filename}\")\n",
        "    else:\n",
        "        print(f\"Failed to fetch: {url}\")\n",
        "\n",
        "# Scrape Hebrew and English texts\n",
        "for link in hebrew_links:\n",
        "    scrape_and_save(link, OUTPUT_DIR_HE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR_EN = \"chabad_texts_english\"\n",
        "os.makedirs(OUTPUT_DIR_EN, exist_ok=True)\n",
        "\n",
        "# Base URL for English texts\n",
        "base_url = \"https://www.chabad.org/library/article_cdo/aid/1757026/jewish/Chassidic-Texts.htm\"\n",
        "\n",
        "# Scraping the index page\n",
        "response = requests.get(base_url)\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    links = [\n",
        "        \"https://www.chabad.org\" + a[\"href\"]\n",
        "        for a in soup.find_all(\"a\", href=True)\n",
        "        if \"/library/article_cdo/\" in a[\"href\"]\n",
        "    ]\n",
        "\n",
        "    # Scrape and save each linked text\n",
        "    for link in links:\n",
        "        try:\n",
        "            res = requests.get(link)\n",
        "            if res.status_code == 200:\n",
        "                page_soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "                text = page_soup.get_text()\n",
        "                filename = os.path.join(OUTPUT_DIR_EN, link.split(\"/\")[-1] + \".txt\")\n",
        "                with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "                    file.write(text)\n",
        "                print(f\"Saved: {filename}\")\n",
        "            else:\n",
        "                print(f\"Failed to fetch {link}: HTTP Status {res.status_code}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Failed to fetch {link}: {str(e)}\")\n",
        "else:\n",
        "    print(f\"Failed to fetch the index page. HTTP Status {response.status_code}\")\n",
        "    if response.status_code == 404:\n",
        "        print(\"Reason: The page does not exist (404).\")\n",
        "    elif response.status_code == 403:\n",
        "        print(\"Reason: Access is forbidden (403).\")\n",
        "    elif response.status_code == 500:\n",
        "        print(\"Reason: Server error (500).\")\n",
        "    else:\n",
        "        print(\"Reason: Unknown error occurred.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTFr7j3tyih",
        "outputId": "a6af95ac-e469-4be9-9b2f-b24c8d56bc8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch the index page. HTTP Status 403\n",
            "Reason: Access is forbidden (403).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q0xtUMbasf_V"
      }
    }
  ]
}